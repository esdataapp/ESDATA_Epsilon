# üõ†Ô∏è Gu√≠a de Soluci√≥n de Problemas - ESDATA_Epsilon

## üéØ Descripci√≥n General

Esta gu√≠a proporciona soluciones paso a paso para los problemas m√°s comunes encontrados al ejecutar el pipeline ESDATA_Epsilon. Incluye diagn√≥sticos, soluciones r√°pidas y prevenci√≥n de errores.

---

## üö® Problemas Cr√≠ticos y Soluciones

### üî• **ERROR CR√çTICO: 'operacion' Column All "Desconocido"**

**S√≠ntomas**:
```bash
# Todas las propiedades muestran operacion = "Desconocido"
df['operacion'].value_counts()
# Desconocido    25851
```

**Causa**: Variable `operacion` en `TEXT_COLUMNS_DESCONOCIDO` siendo sobrescrita

**Soluci√≥n**:
```python
# En step1_consolidar_adecuar.py
# REMOVER 'operacion' de esta lista:
TEXT_COLUMNS_DESCONOCIDO = [
    'direccion', 'colonia', 'descripcion', 'titulo',
    'caracteristicas', 'amenidades', 'servicios', 'exteriores'
    # ‚ùå NO incluir 'operacion' aqu√≠
]

# Verificar mapeo correcto
COLUMN_NAME_MAPPING = {
    'Operaci√≥n': 'operacion',  # ‚úÖ Correcto
    # ‚ùå NO duplicar: 'operacion': 'operacion'
}
```

**Verificaci√≥n**:
```python
python -c "
import pandas as pd
df = pd.read_csv('N1_Tratamiento/Consolidados/Sep25/1.Consolidado_Adecuado_Sep25.csv')
print('Operacion values:', df['operacion'].value_counts())
print('Column position:', list(df.columns).index('operacion'))
"
```

---

### üó∫Ô∏è **ERROR GEOESPACIAL: Inconsistencia sin_colonia vs sin_ciudad**

**S√≠ntomas**:
```bash
# Diferentes conteos para propiedades problem√°ticas
Sin colonia: 998 propiedades
Sin ciudad: 904 propiedades  # ‚ùå Inconsistente
```

**Causa**: Falta de coherencia geoespacial en asignaci√≥n

**Soluci√≥n**:
```python
# En step2_procesamiento_geoespacial.py - Agregar coherencia
def aplicar_coherencia_geoespacial(df):
    """Asegurar coherencia: sin colonia ‚Üí sin ciudad"""
    sin_colonia_mask = df['colonia'] == 'Desconocido'
    
    # Forzar coherencia
    df.loc[sin_colonia_mask, 'Ciudad'] = 'Desconocido'
    
    # Validar resultado
    sin_colonia_count = sin_colonia_mask.sum()
    sin_ciudad_count = (df['Ciudad'] == 'Desconocido').sum()
    
    assert sin_colonia_count == sin_ciudad_count, f"Inconsistencia: {sin_colonia_count} != {sin_ciudad_count}"
    
    return df
```

---

### üí∞ **ERROR PRECIOS: USD No Convertidos**

**S√≠ntomas**:
```bash
# Precios USD sin convertir aparecen como valores bajos
precio: 1650.0  # Deber√≠a ser 33,000 (1650 * 20)
```

**Causa**: Funci√≥n `_extract_precio` no detectando formato USD

**Soluci√≥n**:
```python
def _extract_precio(precio_str):
    """Mejorada detecci√≥n de USD"""
    if pd.isna(precio_str):
        return None
        
    precio_str = str(precio_str).strip()
    
    # Detectar USD en m√∫ltiples formatos
    is_usd = any(indicator in precio_str.upper() for indicator in [
        'USD', 'DOLLAR', '$USD', 'DOLARES', 'DOLAR'
    ])
    
    # Extraer n√∫mero
    numeros = re.findall(r'[\d,]+\.?\d*', precio_str.replace(',', ''))
    if not numeros:
        return None
        
    precio_numerico = float(numeros[0])
    
    # Conversi√≥n USD ‚Üí MN
    if is_usd and precio_numerico < 100000:  # Filtro adicional
        return precio_numerico * 20
    
    return precio_numerico
```

---

### üìä **ERROR CONSISTENCIA: Final_Num ‚â† Final_AME ‚â† Final_MKT**

**S√≠ntomas**:
```bash
Final_Num_Sep25.csv: 24,853 rows
Final_AME_Sep25.csv: 24,800 rows  # ‚ùå Diferente
Final_MKT_Sep25.csv: 24,790 rows  # ‚ùå Diferente
```

**Causa**: Uso de INNER JOIN en lugar de LEFT JOIN

**Soluci√≥n**:
```python
# En step6_remover_duplicados.py - Usar LEFT JOIN
def mantener_consistencia_archivos(ids_finales, df_ame, df_mkt):
    """Asegurar misma cantidad de registros en todos los archivos"""
    
    # LEFT JOIN para preservar todos los IDs finales
    final_ame = pd.merge(ids_finales, df_ame, on='id', how='left')
    final_mkt = pd.merge(ids_finales, df_mkt, on='id', how='left')
    
    # Verificaci√≥n de consistencia
    n_num = len(ids_finales)
    n_ame = len(final_ame)
    n_mkt = len(final_mkt)
    
    assert n_num == n_ame == n_mkt, f"Inconsistencia: {n_num} ‚â† {n_ame} ‚â† {n_mkt}"
    
    return final_ame, final_mkt
```

---

## ‚ö†Ô∏è Errores de Instalaci√≥n

### üîß **ERROR: Microsoft Visual C++ Required (Windows)**

**S√≠ntomas**:
```bash
error: Microsoft Visual C++ 14.0 is required
```

**Soluciones**:

1. **Opci√≥n A - Visual Studio Build Tools**:
```bash
# Descargar e instalar:
# https://visualstudio.microsoft.com/visual-cpp-build-tools/
```

2. **Opci√≥n B - Conda (Recomendado)**:
```bash
conda create -n esdata python=3.10
conda activate esdata
conda install geopandas pandas numpy scipy scikit-learn -c conda-forge
pip install -r requirements.txt
```

3. **Opci√≥n C - Binarios precompilados**:
```bash
pip install --only-binary=all geopandas shapely fiona
```

---

### üó∫Ô∏è **ERROR: GDAL/GEOS Not Found**

**S√≠ntomas**:
```bash
ImportError: Could not find the GDAL/OGR C library
```

**Soluciones por Sistema Operativo**:

#### **Windows**:
```bash
# Opci√≥n 1: Conda (M√°s f√°cil)
conda install gdal geos -c conda-forge

# Opci√≥n 2: OSGeo4W
# Descargar desde: https://trac.osgeo.org/osgeo4w/

# Opci√≥n 3: Binarios precompilados
pip install --find-links https://www.lfd.uci.edu/~gohlke/pythonlibs/ GDAL
```

#### **macOS**:
```bash
# Con Homebrew
brew install gdal geos proj

# Variables de entorno
export GDAL_LIBRARY_PATH=/opt/homebrew/lib/libgdal.dylib
export GEOS_LIBRARY_PATH=/opt/homebrew/lib/libgeos_c.dylib
```

#### **Linux (Ubuntu/Debian)**:
```bash
# Instalar dependencias del sistema
sudo apt-get update
sudo apt-get install gdal-bin libgdal-dev libgeos-dev libproj-dev

# Instalar paquetes Python
pip install GDAL==$(gdal-config --version) geopandas
```

---

### üêç **ERROR: Python Version Compatibility**

**S√≠ntomas**:
```bash
ERROR: No matching distribution found for package==version
```

**Diagn√≥stico**:
```python
import sys
print(f"Python version: {sys.version}")
print(f"Python executable: {sys.executable}")
```

**Soluciones**:

1. **Python 3.12 (Muy nuevo)**:
```bash
# Usar Python 3.10 o 3.11 (m√°s compatible)
pyenv install 3.10.12
pyenv local 3.10.12
```

2. **Python < 3.9 (Muy viejo)**:
```bash
# Actualizar Python
python --version  # Verificar versi√≥n actual
# Instalar Python 3.10+ desde python.org
```

---

## üìÅ Errores de Archivos y Directorios

### üóÇÔ∏è **ERROR: Directory Structure Missing**

**S√≠ntomas**:
```bash
FileNotFoundError: [Errno 2] No such file or directory: 'Base_de_Datos/Sep25/'
```

**Diagn√≥stico**:
```python
from esdata.utils.paths import verificar_estructura
verificar_estructura()
```

**Soluci√≥n**:
```python
from esdata.utils.paths import crear_estructura_directorios
crear_estructura_directorios()
```

---

### üìÑ **ERROR: CSV Reading Issues**

**S√≠ntomas**:
```bash
UnicodeDecodeError: 'utf-8' codec can't decode byte
ParserError: Error tokenizing data
```

**Soluciones**:

1. **Encoding Issues**:
```python
# Detectar encoding
import chardet
with open('archivo.csv', 'rb') as f:
    result = chardet.detect(f.read())
    print(f"Encoding detectado: {result['encoding']}")

# Leer con encoding correcto
df = pd.read_csv('archivo.csv', encoding='latin-1')
```

2. **Delimiters Incorrectos**:
```python
# Detectar delimitador
df = pd.read_csv('archivo.csv', sep=None, engine='python', nrows=5)

# Usar delimitador espec√≠fico
df = pd.read_csv('archivo.csv', delimiter=';')
```

3. **Archivos Corruptos**:
```python
# Leer l√≠nea por l√≠nea para identificar problemas
with open('archivo.csv', 'r', encoding='utf-8', errors='replace') as f:
    for i, line in enumerate(f):
        try:
            # Procesar l√≠nea
            pass
        except Exception as e:
            print(f"Error en l√≠nea {i}: {e}")
```

---

### üó∫Ô∏è **ERROR: GeoJSON Loading Failed**

**S√≠ntomas**:
```bash
fiona.errors.DriverError: unsupported driver: 'GeoJSON'
```

**Soluciones**:

1. **Verificar archivos GeoJSON**:
```python
import geopandas as gpd
import os

geojson_dir = "N1_Tratamiento/Geolocalizacion/GEOJSON"
for file in os.listdir(geojson_dir):
    if file.endswith('.geojson'):
        try:
            gdf = gpd.read_file(os.path.join(geojson_dir, file))
            print(f"‚úÖ {file}: {len(gdf)} pol√≠gonos")
        except Exception as e:
            print(f"‚ùå {file}: {e}")
```

2. **Reparar GeoJSON corrupto**:
```python
import json

def reparar_geojson(archivo):
    try:
        with open(archivo, 'r') as f:
            data = json.load(f)
        
        # Verificar estructura b√°sica
        assert 'type' in data
        assert 'features' in data
        
        print(f"‚úÖ {archivo} v√°lido")
        return True
    except Exception as e:
        print(f"‚ùå {archivo} corrupto: {e}")
        return False
```

---

## üîç Errores de Procesamiento

### üìä **ERROR: Memory Issues with Large Datasets**

**S√≠ntomas**:
```bash
MemoryError: Unable to allocate array
pandas.errors.OutOfMemoryError
```

**Soluciones**:

1. **Chunk Processing**:
```python
def procesar_en_chunks(archivo, chunk_size=5000):
    chunks = []
    for chunk in pd.read_csv(archivo, chunksize=chunk_size):
        # Procesar chunk
        chunk_procesado = procesar_chunk(chunk)
        chunks.append(chunk_procesado)
    
    return pd.concat(chunks, ignore_index=True)
```

2. **Optimizaci√≥n de Tipos**:
```python
def optimizar_tipos(df):
    """Reducir uso de memoria optimizando tipos de datos"""
    for col in df.columns:
        if df[col].dtype == 'int64':
            if df[col].min() > -2147483648 and df[col].max() < 2147483647:
                df[col] = df[col].astype('int32')
        elif df[col].dtype == 'float64':
            df[col] = df[col].astype('float32')
    
    return df
```

3. **Liberar memoria**:
```python
import gc

def limpiar_memoria():
    """Forzar garbage collection"""
    gc.collect()
    
# Usar despu√©s de operaciones pesadas
limpiar_memoria()
```

---

### üî¢ **ERROR: NaN Values in Critical Columns**

**S√≠ntomas**:
```bash
# Muchos valores NaN en columnas cr√≠ticas
precio: 1250 non-null, 500 null
area_m2: 1100 non-null, 650 null
```

**Diagn√≥stico**:
```python
def diagnosticar_nans(df):
    """Analizar valores NaN por columna"""
    nan_summary = df.isnull().sum().sort_values(ascending=False)
    nan_percentage = (nan_summary / len(df) * 100).round(2)
    
    diagnosis = pd.DataFrame({
        'Missing_Count': nan_summary,
        'Missing_Percentage': nan_percentage
    })
    
    return diagnosis[diagnosis['Missing_Count'] > 0]
```

**Soluciones**:

1. **Mejorar extracci√≥n de precios**:
```python
def extract_precio_robusto(precio_str):
    """Extracci√≥n m√°s robusta de precios"""
    if pd.isna(precio_str):
        return None
    
    # M√∫ltiples patrones de b√∫squeda
    patterns = [
        r'[\d,]+\.?\d*',  # N√∫meros con comas
        r'\$\s*[\d,]+',   # Con s√≠mbolo de peso
        r'precio[:\s]+[\d,]+',  # Con palabra precio
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, str(precio_str))
        if matches:
            return float(matches[0].replace(',', '').replace('$', ''))
    
    return None
```

2. **Imputaci√≥n inteligente**:
```python
def imputar_valores_inteligente(df):
    """Imputaci√≥n basada en caracter√≠sticas similares"""
    
    # Imputar √°rea basada en tipo y rec√°maras
    for tipo in df['tipo_propiedad'].unique():
        mask = (df['tipo_propiedad'] == tipo) & df['area_m2'].isna()
        if mask.sum() > 0:
            area_promedio = df[df['tipo_propiedad'] == tipo]['area_m2'].median()
            df.loc[mask, 'area_m2'] = area_promedio
    
    return df
```

---

## üõ†Ô∏è Herramientas de Diagn√≥stico

### üîç **Script de Diagn√≥stico General**

```python
#!/usr/bin/env python3
"""
Script de diagn√≥stico completo para ESDATA_Epsilon
Ejecutar: python diagnostic.py
"""

import pandas as pd
import geopandas as gpd
import os
import sys
from pathlib import Path

def diagnostico_completo():
    """Ejecuta diagn√≥stico completo del sistema"""
    
    print("üîç DIAGN√ìSTICO ESDATA_EPSILON")
    print("=" * 50)
    
    # 1. Verificar Python y dependencias
    print(f"üêç Python: {sys.version}")
    
    dependencias = [
        'pandas', 'numpy', 'geopandas', 'shapely', 
        'scipy', 'sklearn', 'matplotlib', 'seaborn'
    ]
    
    for dep in dependencias:
        try:
            module = __import__(dep)
            version = getattr(module, '__version__', 'unknown')
            print(f"‚úÖ {dep}: {version}")
        except ImportError:
            print(f"‚ùå {dep}: NO INSTALADO")
    
    # 2. Verificar estructura de directorios
    print("\nüìÅ ESTRUCTURA DE DIRECTORIOS:")
    required_dirs = [
        "Base_de_Datos", "N1_Tratamiento", "N2_Estadisticas",
        "N5_Resultados", "Datos_Filtrados"
    ]
    
    for dir_name in required_dirs:
        if os.path.exists(dir_name):
            print(f"‚úÖ {dir_name}/")
        else:
            print(f"‚ùå {dir_name}/ - FALTANTE")
    
    # 3. Verificar archivos GeoJSON
    print("\nüó∫Ô∏è ARCHIVOS GEOJSON:")
    geojson_path = "N1_Tratamiento/Geolocalizacion/GEOJSON"
    if os.path.exists(geojson_path):
        for file in os.listdir(geojson_path):
            if file.endswith('.geojson'):
                try:
                    gdf = gpd.read_file(f"{geojson_path}/{file}")
                    print(f"‚úÖ {file}: {len(gdf)} pol√≠gonos")
                except Exception as e:
                    print(f"‚ùå {file}: ERROR - {e}")
    else:
        print(f"‚ùå Directorio {geojson_path} no existe")
    
    # 4. Verificar archivos de datos m√°s recientes
    print("\nüìä ARCHIVOS DE DATOS:")
    data_patterns = [
        ("N1_Tratamiento/Consolidados/*/1.Consolidado_Adecuado_*.csv", "Consolidado"),
        ("N1_Tratamiento/Consolidados/*/Final_Num_*.csv", "Final_Num"),
        ("N5_Resultados/Nivel_1/CSV/Final_Puntos_*.csv", "Final_Puntos")
    ]
    
    for pattern, name in data_patterns:
        files = list(Path(".").glob(pattern))
        if files:
            latest = max(files, key=os.path.getmtime)
            size_mb = os.path.getsize(latest) / 1024 / 1024
            print(f"‚úÖ {name}: {latest} ({size_mb:.1f} MB)")
        else:
            print(f"‚ùå {name}: No encontrado")
    
    print("\nüéØ DIAGN√ìSTICO COMPLETADO")

if __name__ == "__main__":
    diagnostico_completo()
```

### üîß **Script de Reparaci√≥n Autom√°tica**

```python
#!/usr/bin/env python3
"""
Script de reparaci√≥n autom√°tica para problemas comunes
Ejecutar: python fix_common_issues.py
"""

import os
import pandas as pd
from pathlib import Path

def crear_directorios_faltantes():
    """Crear estructura de directorios requerida"""
    dirs = [
        "Base_de_Datos", "N1_Tratamiento/Consolidados",
        "N2_Estadisticas/Estudios", "N2_Estadisticas/Reportes",
        "N5_Resultados/Nivel_1/CSV", "Datos_Filtrados/Duplicados",
        "Datos_Filtrados/Eliminados", "Datos_Filtrados/Esperando",
        "N1_Tratamiento/Geolocalizacion/GEOJSON"
    ]
    
    for dir_path in dirs:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
        print(f"‚úÖ Directorio creado/verificado: {dir_path}")

def reparar_archivos_corruptos():
    """Intentar reparar archivos CSV corruptos"""
    import chardet
    
    csv_files = list(Path(".").glob("**/*.csv"))
    
    for csv_file in csv_files:
        try:
            # Intentar leer normalmente
            pd.read_csv(csv_file, nrows=5)
            print(f"‚úÖ {csv_file}: OK")
        except Exception as e:
            print(f"‚ö†Ô∏è {csv_file}: Intentando reparar... {e}")
            
            # Detectar encoding
            with open(csv_file, 'rb') as f:
                encoding = chardet.detect(f.read())['encoding']
            
            try:
                # Intentar con encoding detectado
                df = pd.read_csv(csv_file, encoding=encoding, errors='replace')
                
                # Guardar corregido
                backup_file = str(csv_file) + '.backup'
                os.rename(csv_file, backup_file)
                df.to_csv(csv_file, index=False, encoding='utf-8')
                
                print(f"üîß {csv_file}: Reparado (backup: {backup_file})")
            except Exception as e2:
                print(f"‚ùå {csv_file}: No se pudo reparar - {e2}")

def reparacion_completa():
    """Ejecutar todas las reparaciones"""
    print("üîß INICIANDO REPARACI√ìN AUTOM√ÅTICA")
    print("=" * 40)
    
    crear_directorios_faltantes()
    print()
    reparar_archivos_corruptos()
    
    print("\n‚úÖ REPARACI√ìN COMPLETADA")

if __name__ == "__main__":
    reparacion_completa()
```

---

## üìû Soporte y Contacto

### üÜò **Cuando Contactar Soporte**

1. **Errores no cubiertos en esta gu√≠a**
2. **Problemas de rendimiento persistentes**
3. **Bugs en funcionalidades core**
4. **Solicitudes de nuevas caracter√≠sticas**

### üìã **Informaci√≥n a Incluir en Reportes de Bug**

```python
# Template de reporte de bug
print("üêõ REPORTE DE BUG ESDATA_EPSILON")
print("=" * 40)
print(f"Python version: {sys.version}")
print(f"OS: {os.name} {os.uname() if hasattr(os, 'uname') else 'Windows'}")
print(f"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"Paso del pipeline: [ESPECIFICAR]")
print(f"Comando ejecutado: [ESPECIFICAR]")
print(f"Error completo:")
print("[PEGAR TRACEBACK COMPLETO]")
print(f"Archivos de entrada: [LISTAR ARCHIVOS Y TAMA√ëOS]")
print(f"Configuraci√≥n modificada: [S√ç/NO - DETALLAR]")
```

### üîó **Recursos Adicionales**

- **Documentaci√≥n**: `/docs/` directory
- **Configuraci√≥n**: `/docs/CONFIGURACION.md`
- **Flujo de trabajo**: `FLUJO.md`
- **Issues conocidos**: GitHub Issues
- **Actualizaciones**: Changelog en README.md

---

**üõ†Ô∏è Troubleshooting ESDATA_Epsilon** - *Septiembre 2025* ‚ú®

*Esta gu√≠a se actualiza regularmente. Para problemas no cubiertos, consultar documentaci√≥n adicional o contactar soporte t√©cnico.*