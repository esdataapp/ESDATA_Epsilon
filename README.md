# ğŸ  ESDATA_Epsilon - Pipeline Inmobiliario Inteligente

## ğŸ“‹ DescripciÃ³n

ESDATA_Epsilon es un **pipeline completo de procesamiento de datos inmobiliarios** que automatiza la consolidaciÃ³n, estandarizaciÃ³n, validaciÃ³n, anÃ¡lisis geoespacial y generaciÃ³n de reportes para propiedades inmobiliarias en Guadalajara y Zapopan, MÃ©xico.

El sistema procesa datos de mÃºltiples fuentes (principalmente Inmuebles24) y los transforma en informaciÃ³n estructurada y confiable para anÃ¡lisis de mercado inmobiliario.

## ğŸš€ CaracterÃ­sticas Principales

### ğŸ”„ **Pipeline Automatizado**
- **8 pasos secuenciales** de procesamiento de datos
- **Logging comprehensivo** con emojis y estadÃ­sticas detalladas
- **ValidaciÃ³n automÃ¡tica** en cada etapa
- **Manejo de errores** robusto con archivos de respaldo

### ğŸ—ºï¸ **AnÃ¡lisis Geoespacial**
- **AsignaciÃ³n automÃ¡tica** de colonias usando polÃ­gonos GeoJSON
- **ValidaciÃ³n de coordenadas** y detecciÃ³n de inconsistencias
- **CorrecciÃ³n de ubicaciones** basada en geometrÃ­as precisas
- **Cobertura completa** de 1,062 colonias en ambas ciudades

### ğŸ’° **Procesamiento de Precios**
- **ExtracciÃ³n inteligente** de precios con mÃºltiples formatos
- **ConversiÃ³n automÃ¡tica** USD â†’ MN (1 USD = 20 MN)
- **ValidaciÃ³n por rangos** especÃ­ficos por tipo de propiedad
- **DetecciÃ³n de outliers** y valores atÃ­picos

### ğŸ“Š **AnÃ¡lisis EstadÃ­stico**
- **EstadÃ­sticas descriptivas** exhaustivas
- **DetecciÃ³n automÃ¡tica** de tipos de variables
- **AnÃ¡lisis de normalidad** y distribuciones
- **Reportes por colonias** con mÃ©tricas especializadas

### ğŸ¯ **Control de Calidad**
- **Filtrado lÃ³gico** por tipo de propiedad y operaciÃ³n
- **EliminaciÃ³n de duplicados** con criterios jerÃ¡rquicos
- **ValidaciÃ³n cruzada** de consistencia de datos
- **Reportes de propiedades** problemÃ¡ticas

## ğŸ—ï¸ Arquitectura del Pipeline

```mermaid
graph TD
    A[ğŸ“¥ Datos Fuente] --> B[Step 1: ConsolidaciÃ³n]
    B --> C[Step 2: Geoespacial]
    C --> D[Step 3: Versiones Especiales]
    D --> E[Step 4: AnÃ¡lisis de Texto]
    E --> F[Step 5: ValidaciÃ³n LÃ³gica]
    F --> G[Step 6: EliminaciÃ³n Duplicados]
    G --> H[Step 7: EstadÃ­sticas Variables]
    H --> I[Step 8: Resumen Colonias]
    I --> J[ğŸ“Š Reportes Finales]
```

### ğŸ“ **DescripciÃ³n Detallada de Pasos**

| Paso | Nombre | DescripciÃ³n | Entrada | Salida |
|------|--------|-------------|---------|---------|
| **1** | ConsolidaciÃ³n y AdecuaciÃ³n | Unifica archivos CSV, normaliza columnas, estandariza valores, extrae precios USD/MN | MÃºltiples CSV | `1.Consolidado_Adecuado_*.csv` |
| **2** | Procesamiento Geoespacial | Asigna colonias y ciudades usando GeoJSON, valida coordenadas | Consolidado | `2.Consolidado_ConColonia_*.csv` |
| **3** | Versiones Especiales | Genera versiones filtradas para anÃ¡lisis especÃ­ficos | Con Colonias | Versiones especializadas |
| **4** | AnÃ¡lisis de Texto | Procesa variables textuales, extrae caracterÃ­sticas | Versiones | Texto procesado |
| **5** | ValidaciÃ³n LÃ³gica | Aplica filtros de calidad por tipo de propiedad y operaciÃ³n | Texto | `Final_Num_*.csv` |
| **6** | EliminaciÃ³n Duplicados | Remueve duplicados con criterios jerÃ¡rquicos, mantiene consistencia | Validado | `Final_*_*.csv` (3 archivos) |
| **7** | EstadÃ­sticas Variables | Calcula estadÃ­sticas descriptivas por variable | Final | Reportes estadÃ­sticos |
| **8** | Resumen Colonias | Genera reportes por colonia, tablero maestro, puntos finales | EstadÃ­sticas | Reportes por colonia |

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### âœ… **Prerrequisitos**

```bash
Python >= 3.9
pandas >= 1.5.0
geopandas >= 0.12.0
shapely >= 2.0.0
numpy >= 1.21.0
scipy >= 1.7.0
```

### ğŸ“¦ **InstalaciÃ³n**

```bash
# Clonar repositorio
git clone https://github.com/esdataapp/ESDATA_Epsilon.git
cd ESDATA_Epsilon

# Instalar dependencias
pip install -r requirements.txt

# Verificar estructura de directorios
python -c "from esdata.utils.paths import verificar_estructura; verificar_estructura()"
```

### ğŸ—‚ï¸ **Estructura de Directorios**

```
ESDATA_Epsilon/
â”œâ”€â”€ ğŸ“‚ Base_de_Datos/           # Datos fuente por periodo
â”‚   â””â”€â”€ Sep25/                  # Ejemplo: datos Sept 2025
â”œâ”€â”€ ğŸ“‚ N1_Tratamiento/          # Datos procesados
â”‚   â”œâ”€â”€ Consolidados/           # Archivos principales del pipeline
â”‚   â””â”€â”€ Geolocalizacion/        # GeoJSON de colonias
â”œâ”€â”€ ğŸ“‚ N2_Estadisticas/         # Reportes estadÃ­sticos
â”œâ”€â”€ ğŸ“‚ N5_Resultados/           # Resultados finales
â”œâ”€â”€ ğŸ“‚ Datos_Filtrados/         # Propiedades eliminadas
â”œâ”€â”€ ğŸ“‚ esdata/                  # CÃ³digo fuente modular
â”‚   â”œâ”€â”€ pipeline/               # Pasos 1, 3, 5, 6
â”‚   â”œâ”€â”€ geo/                    # Procesamiento geoespacial
â”‚   â”œâ”€â”€ text/                   # AnÃ¡lisis de texto
â”‚   â”œâ”€â”€ estadistica/            # EstadÃ­sticas y reportes
â”‚   â””â”€â”€ utils/                  # Utilidades comunes
â””â”€â”€ ğŸ“‚ docs/                    # DocumentaciÃ³n tÃ©cnica
```

## ğŸš€ Uso del Sistema

### âš¡ **EjecuciÃ³n RÃ¡pida**

```bash
# Ejecutar pipeline completo para periodo Sep25
python -m esdata.pipeline.step1_consolidar_adecuar Sep25
python -m esdata.geo.step2_procesamiento_geoespacial Sep25
python -m esdata.pipeline.step3_versiones_especiales Sep25
python -m esdata.text.step4_analisis_variables_texto Sep25
python -m esdata.pipeline.step5_analisis_logico_corroboracion Sep25
python -m esdata.pipeline.step6_remover_duplicados Sep25
python -m esdata.estadistica.step7_estadisticas_variables Sep25
python -m esdata.estadistica.step8_resumen_colonias Sep25
```

### ğŸ“Š **AnÃ¡lisis de Resultados**

```bash
# Ver estadÃ­sticas generales
python -c "
import pandas as pd
df = pd.read_csv('N5_Resultados/Nivel_1/CSV/Final_Puntos_Sep25.csv')
print(f'Total propiedades: {len(df):,}')
print(f'Ciudades: {df.Ciudad.value_counts()}')
print(f'Tipos: {df.tipo_propiedad.value_counts()}')
print(f'Operaciones: {df.operacion.value_counts()}')
"
```

## ğŸ”§ ConfiguraciÃ³n Avanzada

### ğŸ›ï¸ **Variables de Entorno**

```bash
# Configurar logging
export ESDATA_LOG_LEVEL=INFO
export ESDATA_LOG_FILE=pipeline.log

# Configurar rutas personalizadas
export ESDATA_BASE_PATH=/ruta/personalizada
export ESDATA_GEOJSON_PATH=/ruta/geojson
```

### ğŸ“‹ **Archivos de ConfiguraciÃ³n**

- **`Lista de Variables Orquestacion.csv`**: Mapeos de estandarizaciÃ³n
- **GeoJSON Colonias**: PolÃ­gonos precisos de colonias
- **Condiciones por Tipo**: Rangos de validaciÃ³n en `step5_analisis_logico_corroboracion.py`

## ğŸ† Mejoras Implementadas

### ğŸ”¥ **Recientes (Septiembre 2025)**

1. **ğŸ¯ ExtracciÃ³n de Precios Mejorada**
   - Reconoce formatos: `rentaUSD 1,650`, `ventaMN 10,650,000`
   - ConversiÃ³n automÃ¡tica USDâ†’MN (1:20)
   - **Resultado**: 100% propiedades con precio vÃ¡lido vs 82.5% anterior

2. **ğŸ—ºï¸ Coherencia Geoespacial**
   - LÃ³gica coherente: sin colonia â†’ sin ciudad
   - EliminaciÃ³n de inconsistencias lÃ³gicas
   - **Resultado**: 998 propiedades sin colonia = 998 sin ciudad

3. **ğŸ“Š Logging Comprehensivo**
   - EstadÃ­sticas detalladas en cada paso
   - Emojis para identificaciÃ³n rÃ¡pida
   - Reportes de cobertura y calidad

4. **ğŸ”„ Mapeo de Columnas Robusto**
   - PrevenciÃ³n de pÃ©rdida de datos durante normalizaciÃ³n
   - CombinaciÃ³n inteligente de columnas duplicadas
   - PreservaciÃ³n de datos crÃ­ticos

5. **ğŸ¯ ValidaciÃ³n de Operaciones**
   - CorrecciÃ³n de variable `operacion` con valores reales
   - EliminaciÃ³n de sobrescritura con "Desconocido"
   - **Resultado**: Ven: 22,285 + Ren: 3,566 propiedades

6. **ğŸ“ˆ Tablero Maestro de Colonias**
   - Cobertura completa de 1,062 colonias
   - AnÃ¡lisis de gaps de informaciÃ³n
   - MÃ©tricas de penetraciÃ³n por ciudad

## ğŸ“ˆ MÃ©tricas de Rendimiento

### ğŸ¯ **Calidad de Datos** (Sep25)

| MÃ©trica | Valor | Porcentaje |
|---------|-------|------------|
| **Total propiedades procesadas** | 25,851 | 100% |
| **Con precio vÃ¡lido** | 25,851 | 100% |
| **Con Ã¡rea vÃ¡lida** | 25,781 | 99.7% |
| **Con coordenadas** | 25,815 | 99.9% |
| **Con colonia asignada** | 24,853 | 96.1% |
| **Propiedades finales vÃ¡lidas** | 24,853 | 96.1% |

### ğŸ™ï¸ **DistribuciÃ³n GeogrÃ¡fica**

| Ciudad | Propiedades | Porcentaje | Colonias |
|--------|-------------|------------|----------|
| **Zapopan** | 17,229 | 69.3% | 770 |
| **Guadalajara** | 7,624 | 30.7% | 292 |
| **TOTAL** | 24,853 | 100% | 1,062 |

### ğŸ  **Tipos de Propiedad**

| Tipo | Cantidad | Porcentaje |
|------|----------|------------|
| **Casa (Cas)** | 12,864 | 51.8% |
| **Departamento (Dep)** | 8,084 | 32.5% |
| **Terreno/Lote** | 1,599 | 6.4% |
| **Casa en Condominio (CasC)** | 1,228 | 4.9% |
| **Local Comercial (LocC)** | 668 | 2.7% |
| **Oficina (Ofc)** | 410 | 1.6% |

## ğŸ¤ Contribuciones

### ğŸ”§ **Desarrollo**

1. Fork del repositorio
2. Crear branch: `git checkout -b feature/nueva-funcionalidad`
3. Commit cambios: `git commit -m "Agregar nueva funcionalidad"`
4. Push branch: `git push origin feature/nueva-funcionalidad`
5. Crear Pull Request

### ğŸ› **Reportar Issues**

- Usar templates de issues
- Incluir logs relevantes
- Especificar periodo de datos
- Adjuntar archivos de muestra si es necesario

## ğŸ“š DocumentaciÃ³n Adicional

- **[Flujo de Trabajo](FLUJO.md)**: Proceso detallado paso a paso
- **[ConfiguraciÃ³n](docs/configuracion.md)**: ParÃ¡metros y personalizaciÃ³n
- **[API Reference](docs/api/)**: DocumentaciÃ³n tÃ©cnica de mÃ³dulos
- **[Troubleshooting](docs/troubleshooting.md)**: SoluciÃ³n de problemas comunes

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo [MIT License](LICENSE) - ver archivo para detalles.

---

**ğŸ  ESDATA_Epsilon** - *Pipeline Inmobiliario Inteligente*  
ğŸ“§ Contacto: [esdata@example.com](mailto:esdata@example.com)  
ğŸŒ Sitio Web: [esdata.example.com](https://esdata.example.com)

---

*Ãšltima actualizaciÃ³n: Septiembre 2025* âœ¨ â€“ Plataforma de AnÃ¡lisis Inmobiliario

Pipeline modular + Dashboard analÃ­tico para el estudio de propiedades inmobiliarias (Venta y Renta) en Guadalajara y Zapopan (extensible a otras plazas).

## Objetivo
1. ETL mensual reproducible (10 pasos) con control de calidad y trazabilidad.
2. GeneraciÃ³n de artefactos analÃ­ticos y visualizaciones exploratorias.
3. ProfundizaciÃ³n en variables clave (nuevo mÃ³dulo avanzado `area_m2`).

## Componentes Principales
- **Pipeline ETL (Pasos 1â€“10)**: normaliza, geolocaliza, segmenta variables, valida, deduplica y produce bases finales (`0.Final_*`).
- **MÃ³dulo EstadÃ­stico**: descriptivos, outliers, cuantiles, mÃ©todos representativos, separaciÃ³n colonias.
- **Dashboard Streamlit**: KPIs, confianza de colonias, diferenciaciÃ³n de amenidades, texto/marketing, geoespacial y anÃ¡lisis exhaustivo de Ã¡rea.

## Novedades Recientes (Sep 2025)
- Puntaje de confianza enriquecido (volumen, outliers, dispersiÃ³n IQR/mediana y CV).
- KDE opcional en histogramas.
- Persistencia de prevalencia de amenidades (fallback automÃ¡tico si falta archivo).
- AnÃ¡lisis de texto: frecuencias, TFâ€‘IDF por terciles de PxM2 y nube de palabras.
- SeÃ±ales de marketing (archivo MKT integrado si existe).
- Mapa geoespacial (pydeck) y heatmap Ã¡rea-precio.
- Nuevo mÃ³dulo: **AnÃ¡lisis Exhaustivo `area_m2`** (correlaciones globales, por colonia, estratificaciÃ³n y efecto amenidades).

---

## Estructura Principal de Carpetas (Resumen)
```
Base_de_Datos/               # CSV fuente crudos por mes
Datos_Filtrados/
  Eliminados/
  Duplicados/
  Esperando/                 # Colonias con <5 propiedades acumuladas mes anterior
N1_Tratamiento/
  Consolidados/              # Salidas intermedias pasos 1-6
  Geolocalizacion/
    Colonias/                # GeoJSON colonias
N2_Estadisticas/             # Estudios / Resultados / Reportes (Paso 7)
N5_Resultados/
  Nivel_1/CSV/Tablas/        # Tablas resumen (Pasos 8,10) y finales (Paso 6)
```

## Flujo de Pasos (1â€“10) â€“ Pipeline ETL
| Paso | Script | Entrada Principal | Salidas Clave | Elimina Registros | DescripciÃ³n Breve |
|------|--------|-------------------|---------------|-------------------|-------------------|
| 1 | step1_consolidar_adecuar.py | `Base_de_Datos/*.csv` (+ Esperando previo futuro) | `1.Consolidado_Adecuado_<Per>.csv` | No | Une CSV, normaliza, ID, coords, baÃ±os totales |
| 2 | step2_procesamiento_geoespacial.py | Paso 1 | `2.Consolidado_ConColonia_<Per>.csv` | No (solo marca sin colonia) | Asigna Colonia/Ciudad via GeoJSON |
| 3 | step3_versiones_especiales.py | Paso 2 | `3a.Consolidado_Num_`, `3b.Consolidado_Tex_` | No | Separa variables Num / Texto |
| 4 | step4_analisis_variables_texto.py | 3b | `4a.Tex_Titulo_Descripcion_`, `4b.Tex_Car_Ame_Ser_Ext_` | No | (Placeholder) Extrae mÃ©tricas bÃ¡sicas de texto |
| 5 | step5_analisis_logico_corroboracion.py | 3a + 4a | `5.Num_Corroborado_` + invalidos -> Eliminados | SÃ­ (invalidos precio/area) | Corrobora y reemplaza campos faltantes |
| 6 | step6_remover_duplicados.py | Paso 5 + 4a + 4b | `0.Final_Num_`, `0.Final_MKT_`, `0.Final_Ame_` + duplicados | SÃ­ (duplicados) | DeduplicaciÃ³n y PxM2 |
| 7 | step7_estadisticas_variables.py | `0.Final_Num_` | Descriptivos / Outliers / Normalidad | No | EstadÃ­stica bÃ¡sica precio/area_m2/PxM2 |
| 8 | step8_resumen_colonias.py | `0.Final_Num_` | Resumen inicial/final colonias, Esperando | SÃ­ (mueve <5 a Esperando) | MÃ©tricas min/mean/max y mÃ©todos representativos |
| 9 | step9_separar_colonias.py | `0.Final_Num_` | CSV por colonia jerÃ¡rquico | SÃ­ (mueve <5 a Esperando) | Exporta un CSV por colonia vÃ¡lida |
|10 | step10_metodos_representativos.py | `0.Final_Num_` | `metodos_representativos_<Per>.csv` | No | Ãrbol decisiÃ³n media vs mediana |

## Nomenclatura de Archivos
- Consolidados intermedios: `1.Consolidado_Adecuado_<Per>.csv`, `2.Consolidado_ConColonia_<Per>.csv`, etc.
- Finales: `0.Final_Num_<Per>.csv`, `0.Final_MKT_<Per>.csv`, `0.Final_Ame_<Per>.csv`.
- Resumen colonias: `<Ciudad>_<Oper>_<Tipo>_<Per>_inicial.csv` y `_final.csv`.
- Colonias separadas: `Ciudad_Oper_Tipo_Periodo_COLXXXX.csv` (abreviado a 7 chars).
- MÃ©todos: `metodos_representativos_<Per>.csv`.

## Variables Clave Generadas
- `id`: hash semilla por periodo + atributos (precio, tÃ­tulo, etc.).
- `longitud`, `latitud`: parseadas desde `ubicacion_url`.
- `Banos_totales`: `banos_icon + 0.5 * medio_banos_icon`.
- `PxM2`: `precio / area_m2` (cuando aplica).

## Carpetas de Control de Calidad
- `Datos_Filtrados/Eliminados/<Per>/`: registros sin precio/area vÃ¡lidos o sin colonia (etapa 2 y 5).
- `Datos_Filtrados/Duplicados/<Per>/`: registros descartados por duplicidad (paso 6).
- `Datos_Filtrados/Esperando/<Per>/`: colonias con <5 propiedades (pasos 8 y 9) para acumulaciÃ³n futura.

## EjecuciÃ³n Manual del Pipeline (PowerShell)
Ejecutar en este orden (sustituir `<Per>` por perÃ­odo MesAÃ±o, ej. `Sep25`). Algunos scripts detectan el perÃ­odo automÃ¡ticamente si se omite.
```powershell
python -m esdata.pipeline.step1_consolidar_adecuar
python -m esdata.geo.step2_procesamiento_geoespacial <Per>
python -m esdata.pipeline.step3_versiones_especiales <Per>
python -m esdata.text.step4_analisis_variables_texto <Per>
python -m esdata.pipeline.step5_analisis_logico_corroboracion <Per>
python -m esdata.pipeline.step6_remover_duplicados <Per>
python -m esdata.estadistica.step7_estadisticas_variables <Per>
python -m esdata.estadistica.step8_resumen_colonias <Per>
python -m esdata.estadistica.step9_separar_colonias <Per>
python -m esdata.estadistica.step10_metodos_representativos <Per>
```

## LÃ³gica del Ãrbol Media vs Mediana (Pasos 8 y 10)
- n < 5: No estadÃ­stica / mover a Esperando.
- 5 â‰¤ n < 10: Mediana + rango.
- n â‰¥ 10 y |skew| > 1: Mediana + IQR.
- n â‰¥ 30 y |skew| â‰¤ 0.5: Media + Desv. EstÃ¡ndar.
- Caso intermedio: Mediana + IQR.

## Dashboard Streamlit
### Artefactos necesarios
Generar antes:
```powershell
python -m esdata.dashboard.generate_dashboard_data <Periodo>
```
Esto crea en `Dashboard/CSV/<Periodo>/`:
`colony_stats.csv`, `colony_quantiles.csv`, `outliers_flagged.csv`, `price_area_heatmap_(long|matrix).csv`, `colony_distribution_long.csv`, `amenity_prevalence.csv` (si no existe se genera fallback), `marketing_signals.csv`, `pxm2_evolution_stub.csv`.

### Lanzar Dashboard
```powershell
python -m streamlit run esdata/dashboard/app/app.py -- --periodo <Periodo>
```
Ejemplo:
```powershell
python -m streamlit run esdata/dashboard/app/app.py -- --periodo Sep25
```
Si ejecutas `app.py` directo, se relanza automÃ¡ticamente con Streamlit.

### MÃ³dulos visibles
1. **KPIs & Confianza** â€“ Puntaje 0â€“100 + badge (Muy Alta â†’ Muy Baja).
2. **Outliers & Distribuciones** â€“ Histogramas (opciÃ³n KDE), tabla outliers.
3. **Amenidades (Lift)** â€“ DiferenciaciÃ³n vs ratio global.
4. **Texto & Marketing** â€“ Word frequencies, TFâ€‘IDF segmentado, WordCloud, seÃ±ales MKT.
5. **Geoespacial** â€“ PyDeck + mÃ©tricas por colonia.
6. **Ãrea â€“ AnÃ¡lisis Exhaustivo**:
  - Correlaciones globales (`area_m2` vs numÃ©ricas)
  - EstratificaciÃ³n (bins default en backend; editable en `area_stratification`)
  - Correlaciones por colonia (filtro `min_n`)
  - Efecto amenidades (diferencia mediana del Ã¡rea)
  - Histogramas dinÃ¡micos y sampling automÃ¡tico >50k filas.

### Exportaciones
Botones para descargar correlaciones por colonia y efectos de amenidades. Nomenclatura incluye perÃ­odo.

### Performance & Caching
- Sampling a 50k filas en mÃ³dulo de Ã¡rea para evitar latencia.
- Se puede envolver funciones pesadas con `@st.cache_data` si se estabiliza la lÃ³gica.

## Extensiones Futuras
- Integrar NLP avanzado (amenidades, marketing) en Paso 4.
- Incorporar lectura automÃ¡tica de periodo previo `Esperando` en Paso 1.
- Tests automÃ¡ticos (schema, invariantes de conteo ID, ratio duplicados < X%).
- Export GEOJSON por colonia / niveles (Niveles 2â€“4).

## Dependencias Principales
Ahora se segmentan por entorno para no sobreâ€‘instalar:

| Entorno | Archivo | Contenido principal |
|---------|---------|---------------------|
| Core (pipeline / estadÃ­stica) | `requirements.txt` | pandas, numpy, scipy, scikit-learn, statsmodels, geopandas, text libs bÃ¡sicas |
| Dashboard (UI) | `esdata/dashboard/requirements.txt` | streamlit, plotly, pydeck, wordcloud, bokeh, seaborn, matplotlib |
| Supabase (ingesta) | `Supabase/requirements.txt` | psycopg2-binary, SQLAlchemy, requests, dotenv |

Estrategias de instalaciÃ³n:

1) MÃ¡quina sÃ³lo pipeline:
```powershell
pip install -r requirements.txt
```
2) MÃ¡quina pipeline + dashboard (mismo venv):
```powershell
pip install -r requirements.txt
pip install -r esdata/dashboard/requirements.txt
```
3) MÃ¡quina sÃ³lo dashboard (entorno aislado):
```powershell
pip install -r esdata/dashboard/requirements.txt
# (AÃ±adir pandas/numpy si faltan)
```
4) MÃ¡quina sÃ³lo ingesta Supabase:
```powershell
pip install -r Supabase/requirements.txt
```
5) Todo en entornos separados (recomendado para limpieza):
```
python -m venv .venv_core
.\.venv_core\Scripts\Activate.ps1
pip install -r requirements.txt

python -m venv .venv_dashboard
.\.venv_dashboard\Scripts\Activate.ps1
pip install -r esdata/dashboard/requirements.txt

python -m venv .venv_supabase
.\.venv_supabase\Scripts\Activate.ps1
pip install -r Supabase/requirements.txt
```

Nota: Si compartes venv y ya tenÃ­as instaladas libs pesadas del dashboard, la separaciÃ³n evita replicarlas en mÃ¡quinas donde sÃ³lo se genera el pipeline o se hace ingesta.

## Buenas PrÃ¡cticas Implementadas
- Logging centralizado.
- Modularidad por paso.
- SeparaciÃ³n datos crudos / intermedios / finales.
- Control de pÃ©rdidas (solo se elimina en pasos 5,6,8,9 con trazabilidad).

## MÃ©tricas de Calidad Recomendadas
- % propiedades con coordenadas asignadas.
- % registros eliminados (invÃ¡lidos / duplicados) vs total.
- NÃºmero de colonias en Esperando.
- DistribuciÃ³n de mÃ©todos (media vs mediana) por variable.

## Preguntas Frecuentes
1. Â¿CÃ³mo rehacer solo desde el paso 6? â€” Asegura que existen outputs vÃ¡lidos del paso 5 y vuelve a ejecutar paso 6.
2. Â¿QuÃ© pasa si agrego nuevos CSV al mes? â€” Re-ejecuta desde paso 1; IDs cambian sÃ³lo si cambian los campos semilla.
3. Â¿Por quÃ© algunas colonias no aparecen en el resumen final? â€” Tienen <5 propiedades y se almacenan en `Esperando`.

---
Actualizado: Sep 2025 â€“ Â© 2025 ESDATA_Epsilon
